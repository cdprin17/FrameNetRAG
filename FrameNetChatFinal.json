{"id":"fd250e54-2f15-41b5-825c-62a80b264a29","data":{"nodes":[{"id":"OpenAIModel-yvC5c","type":"genericNode","position":{"x":255.9562588676513,"y":-100.73530136801082},"data":{"type":"OpenAIModel","node":{"template":{"input_value":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Input","advanced":false,"input_types":["Text","Record","Prompt"],"dynamic":false,"info":"","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.constants import STREAM_INFO_TEXT\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import MODEL_NAMES\nfrom langflow.field_typing import NestedDict, Text\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n\n    field_order = [\n        \"max_tokens\",\n        \"model_kwargs\",\n        \"model_name\",\n        \"openai_api_base\",\n        \"openai_api_key\",\n        \"temperature\",\n        \"input_value\",\n        \"system_message\",\n        \"stream\",\n    ]\n\n    def build_config(self):\n        return {\n            \"input_value\": {\"display_name\": \"Input\", \"input_types\": [\"Text\", \"Record\", \"Prompt\"]},\n            \"max_tokens\": {\n                \"display_name\": \"Max Tokens\",\n                \"advanced\": True,\n                \"info\": \"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            },\n            \"model_kwargs\": {\n                \"display_name\": \"Model Kwargs\",\n                \"advanced\": True,\n            },\n            \"model_name\": {\n                \"display_name\": \"Model Name\",\n                \"advanced\": False,\n                \"options\": MODEL_NAMES,\n            },\n            \"openai_api_base\": {\n                \"display_name\": \"OpenAI API Base\",\n                \"advanced\": True,\n                \"info\": (\n                    \"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1.\\n\\n\"\n                    \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\"\n                ),\n            },\n            \"openai_api_key\": {\n                \"display_name\": \"OpenAI API Key\",\n                \"info\": \"The OpenAI API Key to use for the OpenAI model.\",\n                \"advanced\": False,\n                \"password\": True,\n            },\n            \"temperature\": {\n                \"display_name\": \"Temperature\",\n                \"advanced\": False,\n                \"value\": 0.1,\n            },\n            \"stream\": {\n                \"display_name\": \"Stream\",\n                \"info\": STREAM_INFO_TEXT,\n                \"advanced\": True,\n            },\n            \"system_message\": {\n                \"display_name\": \"System Message\",\n                \"info\": \"System message to pass to the model.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        input_value: Text,\n        openai_api_key: str,\n        temperature: float = 0.1,\n        model_name: str = \"gpt-3.5-turbo\",\n        max_tokens: Optional[int] = 256,\n        model_kwargs: NestedDict = {},\n        openai_api_base: Optional[str] = None,\n        stream: bool = False,\n        system_message: Optional[str] = None,\n    ) -> Text:\n        if not openai_api_base:\n            openai_api_base = \"https://api.openai.com/v1\"\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature,\n        )\n\n        return self.get_chat_result(output, stream, input_value, system_message)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"max_tokens":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":256,"fileTypes":[],"file_path":"","password":false,"name":"max_tokens","display_name":"Max Tokens","advanced":true,"dynamic":false,"info":"The maximum number of tokens to generate. Set to 0 for unlimited tokens.","load_from_db":false,"title_case":false},"model_kwargs":{"type":"NestedDict","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":{},"fileTypes":[],"file_path":"","password":false,"name":"model_kwargs","display_name":"Model Kwargs","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"model_name":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"gpt-3.5-turbo","fileTypes":[],"file_path":"","password":false,"options":["gpt-4o","gpt-4-turbo","gpt-4-turbo-preview","gpt-3.5-turbo","gpt-3.5-turbo-0125"],"name":"model_name","display_name":"Model Name","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"openai_api_base":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"openai_api_base","display_name":"OpenAI API Base","advanced":true,"dynamic":false,"info":"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1.\n\nYou can change this to use other APIs like JinaChat, LocalAI and Prem.","load_from_db":false,"title_case":false,"input_types":["Text"]},"openai_api_key":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":true,"name":"openai_api_key","display_name":"OpenAI API Key","advanced":false,"dynamic":false,"info":"The OpenAI API Key to use for the OpenAI model.","load_from_db":false,"title_case":false,"input_types":["Text"],"value":"sk-proj-pB6BuW2SeRViI9Oh7eAlT3BlbkFJUZS4gLxu4TwxIiwiQchE"},"stream":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"stream","display_name":"Stream","advanced":true,"dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","load_from_db":false,"title_case":false},"system_message":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"system_message","display_name":"System Message","advanced":true,"dynamic":false,"info":"System message to pass to the model.","load_from_db":false,"title_case":false,"input_types":["Text"]},"temperature":{"type":"float","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":0.1,"fileTypes":[],"file_path":"","password":false,"name":"temperature","display_name":"Temperature","advanced":false,"dynamic":false,"info":"","rangeSpec":{"step_type":"float","min":-1,"max":1,"step":0.1},"load_from_db":false,"title_case":false},"_type":"CustomComponent"},"description":"Generates text using OpenAI LLMs.","icon":"OpenAI","base_classes":["object","str","Text"],"display_name":"OpenAI","documentation":"","custom_fields":{"input_value":null,"openai_api_key":null,"temperature":null,"model_name":null,"max_tokens":null,"model_kwargs":null,"openai_api_base":null,"stream":null,"system_message":null},"output_types":["Text"],"field_formatters":{},"frozen":false,"field_order":["max_tokens","model_kwargs","model_name","openai_api_base","openai_api_key","temperature","input_value","system_message","stream"],"beta":false,"edited":true},"id":"OpenAIModel-yvC5c","description":"Generates text using OpenAI LLMs.","display_name":"OpenAI","edited":false},"selected":false,"width":384,"height":571,"positionAbsolute":{"x":255.9562588676513,"y":-100.73530136801082},"dragging":false},{"id":"ChatOutput-KoSL6","type":"genericNode","position":{"x":815.1987776053016,"y":-16.39328575966347},"data":{"type":"ChatOutput","node":{"template":{"files":{"type":"file","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[".txt",".md",".mdx",".csv",".json",".yaml",".yml",".xml",".html",".htm",".pdf",".docx",".py",".sh",".sql",".js",".ts",".tsx",".jpg",".jpeg",".png",".bmp"],"file_path":"","password":false,"name":"files","display_name":"Files","advanced":true,"dynamic":false,"info":"Files to be sent with the message.","load_from_db":false,"title_case":false,"value":""},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional, Union\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.field_typing import Text\nfrom langflow.schema.message import Message\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n\n    def build(\n        self,\n        sender: Optional[str] = \"Machine\",\n        sender_name: Optional[str] = \"AI\",\n        input_value: Optional[str] = None,\n        session_id: Optional[str] = None,\n        files: Optional[list[str]] = None,\n        return_message: Optional[bool] = False,\n    ) -> Union[Message, Text]:\n        return super().build_with_record(\n            sender=sender,\n            sender_name=sender_name,\n            input_value=input_value,\n            session_id=session_id,\n            files=files,\n            return_message=return_message,\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Text","advanced":false,"input_types":["Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false},"return_message":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"return_message","display_name":"Return Message","advanced":true,"dynamic":false,"info":"Return the message as a Message containing the sender, sender_name, and session_id.","load_from_db":false,"title_case":false},"sender":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"Machine","fileTypes":[],"file_path":"","password":false,"options":["Machine","User"],"name":"sender","display_name":"Sender Type","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"sender_name":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"AI","fileTypes":[],"file_path":"","password":false,"name":"sender_name","display_name":"Sender Name","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"session_id":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"session_id","display_name":"Session ID","advanced":true,"dynamic":false,"info":"If provided, the message will be stored in the memory.","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Display a chat message in the Playground.","icon":"ChatOutput","base_classes":["Message","object","str","Text"],"display_name":"Chat Output","documentation":"","custom_fields":{"sender":null,"sender_name":null,"input_value":null,"session_id":null,"files":null,"return_message":null},"output_types":["Message","Text"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false,"edited":true},"id":"ChatOutput-KoSL6","description":"Display a chat message in the Playground.","display_name":"Chat Output","edited":false},"selected":false,"width":384,"height":296,"positionAbsolute":{"x":815.1987776053016,"y":-16.39328575966347},"dragging":false},{"id":"Prompt-wb1Kn","type":"genericNode","position":{"x":-300.85711385557136,"y":-84.33337297312754},"data":{"type":"Prompt","node":{"template":{"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langchain_core.prompts import PromptTemplate\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import Prompt, TemplateField, Text\n\n\nclass PromptComponent(CustomComponent):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n\n    def build_config(self):\n        return {\n            \"template\": TemplateField(display_name=\"Template\"),\n            \"code\": TemplateField(advanced=True),\n        }\n\n    def build(\n        self,\n        template: Prompt,\n        **kwargs,\n    ) -> Text:\n        from langflow.base.prompts.utils import dict_values_to_string\n\n        prompt_template = PromptTemplate.from_template(Text(template))\n        kwargs = dict_values_to_string(kwargs)\n        kwargs = {k: \"\\n\".join(v) if isinstance(v, list) else v for k, v in kwargs.items()}\n        try:\n            formated_prompt = prompt_template.format(**kwargs)\n        except Exception as exc:\n            raise ValueError(f\"Error formatting prompt: {exc}\") from exc\n        self.status = f'Prompt:\\n\"{formated_prompt}\"'\n        return formated_prompt\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"template":{"type":"prompt","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":" You are an expert linguistic assistant and problem-solver, tasked with answering any question about the FrameNet version 1.7 database.\n\nAnswer the question using the context below:\n\nQuestion: {Question}\n\nContext: {Context}\n\nGenerate a comprehensive and informative answer to the given question based solely on the provided search results (URL and context). You must only use information from the provided search results. Combine search results together into a coherent answer. Do not repeat text. Only output the most relevant and accurate results that answer the question. If different results refer to different entities within the same name, write separate answers for each entity. Cite search results using [${{number}}] notation. If there is nothing in the context relevant to the question at hand, just say \"Hmm, I'm not sure.\" Don't try to make up an answer.\n\nAnything between the following retrieved from the \"Context\" prompt variable is retrieved from a knowledge bank, not part of the conversation with the user.\nREMEMBER: If there is no relevant information within the context, just say \"Hmm, I'm not sure.\" Don't try to make up an answer. Anything retrieved from the \"Context\" prompt variable is retrieved from a knowledge bank, not part of the conversation with the user.\n\nImportant definitions for frame relationships are as follows:\nInheritance: An IS-A relation. The child frame is a subtype of the parent frame, and each FE in the parent is bound to a corresponding FE in the child. An example is the “Revenge” frame which inherits from the “Rewards_and_punishments” frame.\nUsing: The child frame presupposes the parent frame as background, e.g the “Speed” frame “uses” (or presupposes) the “Motion” frame; however, not all parent FEs need to be bound to child FEs.\nSubframe: The child frame is a subevent of a complex event represented by the parent, e.g. the “Criminal_process” frame has subframes of “Arrest”, “Arraignment”, “Trial”, and “Sentencing”.\nPerspective_on: The child frame provides a particular perspective on an un-perspectivized parent frame. A pair of examples consists of the “Hiring” and “Get_a_job” frames, which perspectivize the “Employment_start” frame from the Employer’s and the Employee’s point of view, respectively.\nPrecedes: The temporal ordering of subevents within a complex event. The relation holds between component subframes of a single complex frame, and provides additional information on the set of subframe relations. For example, Being_awake precedes Falling_asleep.\nCausative_of: The mother frame represents a version of the daughter frame where the agent or cause of the event represented by the frame is profiled. This relation allows for inferring some systematic cause-effect processes.\nInchoative_of: Also related to cause-effect processes, this relation indicates that the mother frame depicts a change of state scene whose result is the daughter frame.\n\n\n","fileTypes":[],"file_path":"","password":false,"name":"template","display_name":"Template","advanced":false,"input_types":["Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false},"_type":"CustomComponent","Question":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"Question","display_name":"Question","advanced":false,"input_types":["Document","Record","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"},"Context":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"Context","display_name":"Context","advanced":false,"input_types":["Document","Record","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"}},"description":"Create a prompt template with dynamic variables.","icon":"prompts","is_input":null,"is_output":null,"is_composition":null,"base_classes":["object","str","Text"],"name":"","display_name":"Prompt","documentation":"","custom_fields":{"template":["Question","Context"]},"output_types":["Text"],"full_path":null,"field_formatters":{},"frozen":false,"field_order":[],"beta":false,"error":null},"id":"Prompt-wb1Kn","description":"Create a prompt template with dynamic variables.","display_name":"Prompt"},"selected":false,"width":384,"height":513,"positionAbsolute":{"x":-300.85711385557136,"y":-84.33337297312754},"dragging":false},{"id":"CharacterTextSplitter-Q5DKn","type":"genericNode","position":{"x":-295.3292476782598,"y":-1212.17898825244},"data":{"type":"CharacterTextSplitter","node":{"template":{"inputs":{"type":"Record","required":true,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"inputs","display_name":"Input","advanced":false,"input_types":["Document","Record"],"dynamic":false,"info":"","load_from_db":false,"title_case":false},"chunk_overlap":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"0","fileTypes":[],"file_path":"","password":false,"name":"chunk_overlap","display_name":"Chunk Overlap","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"chunk_size":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"1","fileTypes":[],"file_path":"","password":false,"name":"chunk_size","display_name":"Chunk Size","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import List\n\nfrom langchain_text_splitters import CharacterTextSplitter\n\nfrom langflow.custom import CustomComponent\nfrom langflow.schema.schema import Record\nfrom langflow.utils.util import unescape_string\n\n\nclass CharacterTextSplitterComponent(CustomComponent):\n    display_name = \"CharacterTextSplitter\"\n    description = \"Splitting text that looks at characters.\"\n\n    def build_config(self):\n        return {\n            \"inputs\": {\"display_name\": \"Input\", \"input_types\": [\"Document\", \"Record\"]},\n            \"chunk_overlap\": {\"display_name\": \"Chunk Overlap\", \"default\": 200},\n            \"chunk_size\": {\"display_name\": \"Chunk Size\", \"default\": 1000},\n            \"separator\": {\"display_name\": \"Separator\", \"default\": \"\\n\"},\n        }\n\n    def build(\n        self,\n        inputs: List[Record],\n        chunk_overlap: int = 200,\n        chunk_size: int = 1000,\n        separator: str = \"\\n\",\n    ) -> List[Record]:\n        # separator may come escaped from the frontend\n        separator = unescape_string(separator)\n        documents = []\n        for _input in inputs:\n            if isinstance(_input, Record):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n        docs = CharacterTextSplitter(\n            chunk_overlap=chunk_overlap,\n            chunk_size=chunk_size,\n            separator=separator,\n        ).split_documents(documents)\n        records = self.to_records(docs)\n        self.status = records\n        return records\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"separator":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"BREAK","fileTypes":[],"file_path":"","password":false,"name":"separator","display_name":"Separator","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Splitting text that looks at characters.","base_classes":["Record"],"display_name":"CharacterTextSplitter","documentation":"","custom_fields":{"inputs":null,"chunk_overlap":null,"chunk_size":null,"separator":null},"output_types":["Record"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"CharacterTextSplitter-Q5DKn"},"selected":false,"width":384,"height":515,"dragging":false,"positionAbsolute":{"x":-295.3292476782598,"y":-1212.17898825244}},{"id":"AstraDB-qYfmn","type":"genericNode","position":{"x":232.2043934002752,"y":-1138.9951899003186},"data":{"type":"AstraDB","node":{"template":{"embedding":{"type":"Embeddings","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"embedding","display_name":"Embedding","advanced":false,"dynamic":false,"info":"Embedding to use","load_from_db":false,"title_case":false},"inputs":{"type":"Record","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"inputs","display_name":"Inputs","advanced":false,"dynamic":false,"info":"Optional list of records to be processed and stored in the vector store.","load_from_db":false,"title_case":false},"api_endpoint":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"api_endpoint","display_name":"API Endpoint","advanced":false,"dynamic":false,"info":"API endpoint URL for the Astra DB service.","load_from_db":false,"title_case":false,"input_types":["Text"],"value":"https://51209aa4-4370-415e-8957-490ca8fa2cc6-us-east-2.apps.astra.datastax.com"},"batch_size":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"batch_size","display_name":"Batch Size","advanced":true,"dynamic":false,"info":"Optional number of records to process in a single batch.","load_from_db":false,"title_case":false},"bulk_delete_concurrency":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"bulk_delete_concurrency","display_name":"Bulk Delete Concurrency","advanced":true,"dynamic":false,"info":"Optional concurrency level for bulk delete operations.","load_from_db":false,"title_case":false},"bulk_insert_batch_concurrency":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"bulk_insert_batch_concurrency","display_name":"Bulk Insert Batch Concurrency","advanced":true,"dynamic":false,"info":"Optional concurrency level for bulk insert operations.","load_from_db":false,"title_case":false},"bulk_insert_overwrite_concurrency":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"bulk_insert_overwrite_concurrency","display_name":"Bulk Insert Overwrite Concurrency","advanced":true,"dynamic":false,"info":"Optional concurrency level for bulk insert operations that overwrite existing records.","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import List, Optional, Union\nfrom langchain_astradb import AstraDBVectorStore\nfrom langchain_astradb.utils.astradb import SetupMode\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import Embeddings, VectorStore\nfrom langflow.schema import Record\nfrom langchain_core.retrievers import BaseRetriever\n\n\nclass AstraDBVectorStoreComponent(CustomComponent):\n    display_name = \"Astra DB\"\n    description = \"Builds or loads an Astra DB Vector Store.\"\n    icon = \"AstraDB\"\n    field_order = [\"token\", \"api_endpoint\", \"collection_name\", \"inputs\", \"embedding\"]\n\n    def build_config(self):\n        return {\n            \"inputs\": {\n                \"display_name\": \"Inputs\",\n                \"info\": \"Optional list of records to be processed and stored in the vector store.\",\n            },\n            \"embedding\": {\"display_name\": \"Embedding\", \"info\": \"Embedding to use\"},\n            \"collection_name\": {\n                \"display_name\": \"Collection Name\",\n                \"info\": \"The name of the collection within Astra DB where the vectors will be stored.\",\n            },\n            \"token\": {\n                \"display_name\": \"Token\",\n                \"info\": \"Authentication token for accessing Astra DB.\",\n                \"password\": True,\n            },\n            \"api_endpoint\": {\n                \"display_name\": \"API Endpoint\",\n                \"info\": \"API endpoint URL for the Astra DB service.\",\n            },\n            \"namespace\": {\n                \"display_name\": \"Namespace\",\n                \"info\": \"Optional namespace within Astra DB to use for the collection.\",\n                \"advanced\": True,\n            },\n            \"metric\": {\n                \"display_name\": \"Metric\",\n                \"info\": \"Optional distance metric for vector comparisons in the vector store.\",\n                \"advanced\": True,\n            },\n            \"batch_size\": {\n                \"display_name\": \"Batch Size\",\n                \"info\": \"Optional number of records to process in a single batch.\",\n                \"advanced\": True,\n            },\n            \"bulk_insert_batch_concurrency\": {\n                \"display_name\": \"Bulk Insert Batch Concurrency\",\n                \"info\": \"Optional concurrency level for bulk insert operations.\",\n                \"advanced\": True,\n            },\n            \"bulk_insert_overwrite_concurrency\": {\n                \"display_name\": \"Bulk Insert Overwrite Concurrency\",\n                \"info\": \"Optional concurrency level for bulk insert operations that overwrite existing records.\",\n                \"advanced\": True,\n            },\n            \"bulk_delete_concurrency\": {\n                \"display_name\": \"Bulk Delete Concurrency\",\n                \"info\": \"Optional concurrency level for bulk delete operations.\",\n                \"advanced\": True,\n            },\n            \"setup_mode\": {\n                \"display_name\": \"Setup Mode\",\n                \"info\": \"Configuration mode for setting up the vector store, with options like “Sync”, “Async”, or “Off”.\",\n                \"options\": [\"Sync\", \"Async\", \"Off\"],\n                \"advanced\": True,\n            },\n            \"pre_delete_collection\": {\n                \"display_name\": \"Pre Delete Collection\",\n                \"info\": \"Boolean flag to determine whether to delete the collection before creating a new one.\",\n                \"advanced\": True,\n            },\n            \"metadata_indexing_include\": {\n                \"display_name\": \"Metadata Indexing Include\",\n                \"info\": \"Optional list of metadata fields to include in the indexing.\",\n                \"advanced\": True,\n            },\n            \"metadata_indexing_exclude\": {\n                \"display_name\": \"Metadata Indexing Exclude\",\n                \"info\": \"Optional list of metadata fields to exclude from the indexing.\",\n                \"advanced\": True,\n            },\n            \"collection_indexing_policy\": {\n                \"display_name\": \"Collection Indexing Policy\",\n                \"info\": \"Optional dictionary defining the indexing policy for the collection.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        embedding: Embeddings,\n        token: str,\n        api_endpoint: str,\n        collection_name: str,\n        inputs: Optional[List[Record]] = None,\n        namespace: Optional[str] = None,\n        metric: Optional[str] = None,\n        batch_size: Optional[int] = None,\n        bulk_insert_batch_concurrency: Optional[int] = None,\n        bulk_insert_overwrite_concurrency: Optional[int] = None,\n        bulk_delete_concurrency: Optional[int] = None,\n        setup_mode: str = \"Sync\",\n        pre_delete_collection: bool = False,\n        metadata_indexing_include: Optional[List[str]] = None,\n        metadata_indexing_exclude: Optional[List[str]] = None,\n        collection_indexing_policy: Optional[dict] = None,\n    ) -> Union[VectorStore, BaseRetriever]:\n        try:\n            setup_mode_value = SetupMode[setup_mode.upper()]\n        except KeyError:\n            raise ValueError(f\"Invalid setup mode: {setup_mode}\")\n        if inputs:\n            documents = [_input.to_lc_document() for _input in inputs]\n\n            vector_store = AstraDBVectorStore.from_documents(\n                documents=documents,\n                embedding=embedding,\n                collection_name=collection_name,\n                token=token,\n                api_endpoint=api_endpoint,\n                namespace=namespace,\n                metric=metric,\n                batch_size=batch_size,\n                bulk_insert_batch_concurrency=bulk_insert_batch_concurrency,\n                bulk_insert_overwrite_concurrency=bulk_insert_overwrite_concurrency,\n                bulk_delete_concurrency=bulk_delete_concurrency,\n                setup_mode=setup_mode_value,\n                pre_delete_collection=pre_delete_collection,\n                metadata_indexing_include=metadata_indexing_include,\n                metadata_indexing_exclude=metadata_indexing_exclude,\n                collection_indexing_policy=collection_indexing_policy,\n            )\n        else:\n            vector_store = AstraDBVectorStore(\n                embedding=embedding,\n                collection_name=collection_name,\n                token=token,\n                api_endpoint=api_endpoint,\n                namespace=namespace,\n                metric=metric,\n                batch_size=batch_size,\n                bulk_insert_batch_concurrency=bulk_insert_batch_concurrency,\n                bulk_insert_overwrite_concurrency=bulk_insert_overwrite_concurrency,\n                bulk_delete_concurrency=bulk_delete_concurrency,\n                setup_mode=setup_mode_value,\n                pre_delete_collection=pre_delete_collection,\n                metadata_indexing_include=metadata_indexing_include,\n                metadata_indexing_exclude=metadata_indexing_exclude,\n                collection_indexing_policy=collection_indexing_policy,\n            )\n\n        return vector_store\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"collection_indexing_policy":{"type":"dict","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"collection_indexing_policy","display_name":"Collection Indexing Policy","advanced":true,"dynamic":false,"info":"Optional dictionary defining the indexing policy for the collection.","load_from_db":false,"title_case":false},"collection_name":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"collection_name","display_name":"Collection Name","advanced":false,"dynamic":false,"info":"The name of the collection within Astra DB where the vectors will be stored.","load_from_db":false,"title_case":false,"input_types":["Text"],"value":"framennet2"},"metadata_indexing_exclude":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"metadata_indexing_exclude","display_name":"Metadata Indexing Exclude","advanced":true,"dynamic":false,"info":"Optional list of metadata fields to exclude from the indexing.","load_from_db":false,"title_case":false,"input_types":["Text"]},"metadata_indexing_include":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"metadata_indexing_include","display_name":"Metadata Indexing Include","advanced":true,"dynamic":false,"info":"Optional list of metadata fields to include in the indexing.","load_from_db":false,"title_case":false,"input_types":["Text"]},"metric":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"metric","display_name":"Metric","advanced":true,"dynamic":false,"info":"Optional distance metric for vector comparisons in the vector store.","load_from_db":false,"title_case":false,"input_types":["Text"]},"namespace":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"namespace","display_name":"Namespace","advanced":true,"dynamic":false,"info":"Optional namespace within Astra DB to use for the collection.","load_from_db":false,"title_case":false,"input_types":["Text"]},"pre_delete_collection":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"pre_delete_collection","display_name":"Pre Delete Collection","advanced":true,"dynamic":false,"info":"Boolean flag to determine whether to delete the collection before creating a new one.","load_from_db":false,"title_case":false},"setup_mode":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"Sync","fileTypes":[],"file_path":"","password":false,"options":["Sync","Async","Off"],"name":"setup_mode","display_name":"Setup Mode","advanced":true,"dynamic":false,"info":"Configuration mode for setting up the vector store, with options like “Sync”, “Async”, or “Off”.","load_from_db":false,"title_case":false,"input_types":["Text"]},"token":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":true,"name":"token","display_name":"Token","advanced":false,"dynamic":false,"info":"Authentication token for accessing Astra DB.","load_from_db":false,"title_case":false,"input_types":["Text"],"value":"AstraCS:xSBzPYWCwpdahHGQGMdtEcvi:3f2426b2835e7e53fe115d976ba8e7226c97df7c9143a820ac195f50348d3872"},"_type":"CustomComponent"},"description":"Builds or loads an Astra DB Vector Store.","icon":"AstraDB","base_classes":["BaseRetriever","Generic","object","Runnable","RunnableSerializable","Serializable","VectorStore"],"display_name":"Astra DB","documentation":"","custom_fields":{"embedding":null,"token":null,"api_endpoint":null,"collection_name":null,"inputs":null,"namespace":null,"metric":null,"batch_size":null,"bulk_insert_batch_concurrency":null,"bulk_insert_overwrite_concurrency":null,"bulk_delete_concurrency":null,"setup_mode":null,"pre_delete_collection":null,"metadata_indexing_include":null,"metadata_indexing_exclude":null,"collection_indexing_policy":null},"output_types":["VectorStore","BaseRetriever"],"field_formatters":{},"frozen":false,"field_order":["token","api_endpoint","collection_name","inputs","embedding"],"beta":false},"id":"AstraDB-qYfmn"},"selected":false,"width":384,"height":579,"positionAbsolute":{"x":232.2043934002752,"y":-1138.9951899003186},"dragging":false},{"id":"OpenAIEmbeddings-78poi","type":"genericNode","position":{"x":-300.61310516136183,"y":-549.5138673904489},"data":{"type":"OpenAIEmbeddings","node":{"template":{"allowed_special":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":[],"fileTypes":[],"file_path":"","password":false,"name":"allowed_special","display_name":"Allowed Special","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"chunk_size":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":1000,"fileTypes":[],"file_path":"","password":false,"name":"chunk_size","display_name":"Chunk Size","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Dict, List, Optional\n\nfrom langchain_openai.embeddings.base import OpenAIEmbeddings\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import Embeddings, NestedDict\n\n\nclass OpenAIEmbeddingsComponent(CustomComponent):\n    display_name = \"OpenAI Embeddings\"\n    description = \"Generate embeddings using OpenAI models.\"\n\n    def build_config(self):\n        return {\n            \"allowed_special\": {\n                \"display_name\": \"Allowed Special\",\n                \"advanced\": True,\n                \"field_type\": \"str\",\n                \"is_list\": True,\n            },\n            \"default_headers\": {\n                \"display_name\": \"Default Headers\",\n                \"advanced\": True,\n                \"field_type\": \"dict\",\n            },\n            \"default_query\": {\n                \"display_name\": \"Default Query\",\n                \"advanced\": True,\n                \"field_type\": \"NestedDict\",\n            },\n            \"disallowed_special\": {\n                \"display_name\": \"Disallowed Special\",\n                \"advanced\": True,\n                \"field_type\": \"str\",\n                \"is_list\": True,\n            },\n            \"chunk_size\": {\"display_name\": \"Chunk Size\", \"advanced\": True},\n            \"client\": {\"display_name\": \"Client\", \"advanced\": True},\n            \"deployment\": {\"display_name\": \"Deployment\", \"advanced\": True},\n            \"embedding_ctx_length\": {\n                \"display_name\": \"Embedding Context Length\",\n                \"advanced\": True,\n            },\n            \"max_retries\": {\"display_name\": \"Max Retries\", \"advanced\": True},\n            \"model\": {\n                \"display_name\": \"Model\",\n                \"advanced\": False,\n                \"options\": [\n                    \"text-embedding-3-small\",\n                    \"text-embedding-3-large\",\n                    \"text-embedding-ada-002\",\n                ],\n            },\n            \"model_kwargs\": {\"display_name\": \"Model Kwargs\", \"advanced\": True},\n            \"openai_api_base\": {\n                \"display_name\": \"OpenAI API Base\",\n                \"password\": True,\n                \"advanced\": True,\n            },\n            \"openai_api_key\": {\"display_name\": \"OpenAI API Key\", \"password\": True},\n            \"openai_api_type\": {\n                \"display_name\": \"OpenAI API Type\",\n                \"advanced\": True,\n                \"password\": True,\n            },\n            \"openai_api_version\": {\n                \"display_name\": \"OpenAI API Version\",\n                \"advanced\": True,\n            },\n            \"openai_organization\": {\n                \"display_name\": \"OpenAI Organization\",\n                \"advanced\": True,\n            },\n            \"openai_proxy\": {\"display_name\": \"OpenAI Proxy\", \"advanced\": True},\n            \"request_timeout\": {\"display_name\": \"Request Timeout\", \"advanced\": True},\n            \"show_progress_bar\": {\n                \"display_name\": \"Show Progress Bar\",\n                \"advanced\": True,\n            },\n            \"skip_empty\": {\"display_name\": \"Skip Empty\", \"advanced\": True},\n            \"tiktoken_model_name\": {\n                \"display_name\": \"TikToken Model Name\",\n                \"advanced\": True,\n            },\n            \"tiktoken_enable\": {\"display_name\": \"TikToken Enable\", \"advanced\": True},\n        }\n\n    def build(\n        self,\n        openai_api_key: str,\n        default_headers: Optional[Dict[str, str]] = None,\n        default_query: Optional[NestedDict] = {},\n        allowed_special: List[str] = [],\n        disallowed_special: List[str] = [\"all\"],\n        chunk_size: int = 1000,\n        deployment: str = \"text-embedding-ada-002\",\n        embedding_ctx_length: int = 8191,\n        max_retries: int = 6,\n        model: str = \"text-embedding-ada-002\",\n        model_kwargs: NestedDict = {},\n        openai_api_base: Optional[str] = None,\n        openai_api_type: Optional[str] = None,\n        openai_api_version: Optional[str] = None,\n        openai_organization: Optional[str] = None,\n        openai_proxy: Optional[str] = None,\n        request_timeout: Optional[float] = None,\n        show_progress_bar: bool = False,\n        skip_empty: bool = False,\n        tiktoken_enable: bool = True,\n        tiktoken_model_name: Optional[str] = None,\n    ) -> Embeddings:\n        # This is to avoid errors with Vector Stores (e.g Chroma)\n        if disallowed_special == [\"all\"]:\n            disallowed_special = \"all\"  # type: ignore\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n\n        return OpenAIEmbeddings(\n            tiktoken_enabled=tiktoken_enable,\n            default_headers=default_headers,\n            default_query=default_query,\n            allowed_special=set(allowed_special),\n            disallowed_special=\"all\",\n            chunk_size=chunk_size,\n            deployment=deployment,\n            embedding_ctx_length=embedding_ctx_length,\n            max_retries=max_retries,\n            model=model,\n            model_kwargs=model_kwargs,\n            base_url=openai_api_base,\n            api_key=api_key,\n            openai_api_type=openai_api_type,\n            api_version=openai_api_version,\n            organization=openai_organization,\n            openai_proxy=openai_proxy,\n            timeout=request_timeout,\n            show_progress_bar=show_progress_bar,\n            skip_empty=skip_empty,\n            tiktoken_model_name=tiktoken_model_name,\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"default_headers":{"type":"dict","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"default_headers","display_name":"Default Headers","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"default_query":{"type":"NestedDict","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":{},"fileTypes":[],"file_path":"","password":false,"name":"default_query","display_name":"Default Query","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"deployment":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"text-embedding-ada-002","fileTypes":[],"file_path":"","password":false,"name":"deployment","display_name":"Deployment","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"disallowed_special":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":["all"],"fileTypes":[],"file_path":"","password":false,"name":"disallowed_special","display_name":"Disallowed Special","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"embedding_ctx_length":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":8191,"fileTypes":[],"file_path":"","password":false,"name":"embedding_ctx_length","display_name":"Embedding Context Length","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"max_retries":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":6,"fileTypes":[],"file_path":"","password":false,"name":"max_retries","display_name":"Max Retries","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"model":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"text-embedding-ada-002","fileTypes":[],"file_path":"","password":false,"options":["text-embedding-3-small","text-embedding-3-large","text-embedding-ada-002"],"name":"model","display_name":"Model","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"model_kwargs":{"type":"NestedDict","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":{},"fileTypes":[],"file_path":"","password":false,"name":"model_kwargs","display_name":"Model Kwargs","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"openai_api_base":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":true,"name":"openai_api_base","display_name":"OpenAI API Base","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"openai_api_key":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":true,"name":"openai_api_key","display_name":"OpenAI API Key","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"],"value":"sk-proj-pB6BuW2SeRViI9Oh7eAlT3BlbkFJUZS4gLxu4TwxIiwiQchE"},"openai_api_type":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":true,"name":"openai_api_type","display_name":"OpenAI API Type","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"openai_api_version":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"openai_api_version","display_name":"OpenAI API Version","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"openai_organization":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"openai_organization","display_name":"OpenAI Organization","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"openai_proxy":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"openai_proxy","display_name":"OpenAI Proxy","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"request_timeout":{"type":"float","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"request_timeout","display_name":"Request Timeout","advanced":true,"dynamic":false,"info":"","rangeSpec":{"step_type":"float","min":-1,"max":1,"step":0.1},"load_from_db":false,"title_case":false},"show_progress_bar":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"show_progress_bar","display_name":"Show Progress Bar","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"skip_empty":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"skip_empty","display_name":"Skip Empty","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"tiktoken_enable":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":true,"fileTypes":[],"file_path":"","password":false,"name":"tiktoken_enable","display_name":"TikToken Enable","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"tiktoken_model_name":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"tiktoken_model_name","display_name":"TikToken Model Name","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Generate embeddings using OpenAI models.","base_classes":["Embeddings"],"display_name":"OpenAI Embeddings","documentation":"","custom_fields":{"openai_api_key":null,"default_headers":null,"default_query":null,"allowed_special":null,"disallowed_special":null,"chunk_size":null,"deployment":null,"embedding_ctx_length":null,"max_retries":null,"model":null,"model_kwargs":null,"openai_api_base":null,"openai_api_type":null,"openai_api_version":null,"openai_organization":null,"openai_proxy":null,"request_timeout":null,"show_progress_bar":null,"skip_empty":null,"tiktoken_enable":null,"tiktoken_model_name":null},"output_types":["Embeddings"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"OpenAIEmbeddings-78poi"},"selected":false,"width":384,"height":389,"positionAbsolute":{"x":-300.61310516136183,"y":-549.5138673904489},"dragging":false},{"id":"AstraDBSearch-y9bNG","type":"genericNode","position":{"x":-920.0998977094329,"y":-426.7905927534177},"data":{"type":"AstraDBSearch","node":{"template":{"embedding":{"type":"Embeddings","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"embedding","display_name":"Embedding","advanced":false,"dynamic":false,"info":"Embedding to use","load_from_db":false,"title_case":false},"input_value":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Input Value","advanced":false,"dynamic":false,"info":"Input value to search","load_from_db":false,"title_case":false,"input_types":["Text"],"value":""},"api_endpoint":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"api_endpoint","display_name":"API Endpoint","advanced":false,"dynamic":false,"info":"API endpoint URL for the Astra DB service.","load_from_db":false,"title_case":false,"input_types":["Text"],"value":"https://51209aa4-4370-415e-8957-490ca8fa2cc6-us-east-2.apps.astra.datastax.com"},"batch_size":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"batch_size","display_name":"Batch Size","advanced":true,"dynamic":false,"info":"Optional number of records to process in a single batch.","load_from_db":false,"title_case":false},"bulk_delete_concurrency":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"bulk_delete_concurrency","display_name":"Bulk Delete Concurrency","advanced":true,"dynamic":false,"info":"Optional concurrency level for bulk delete operations.","load_from_db":false,"title_case":false},"bulk_insert_batch_concurrency":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"bulk_insert_batch_concurrency","display_name":"Bulk Insert Batch Concurrency","advanced":true,"dynamic":false,"info":"Optional concurrency level for bulk insert operations.","load_from_db":false,"title_case":false},"bulk_insert_overwrite_concurrency":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"bulk_insert_overwrite_concurrency","display_name":"Bulk Insert Overwrite Concurrency","advanced":true,"dynamic":false,"info":"Optional concurrency level for bulk insert operations that overwrite existing records.","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import List, Optional\n\nfrom langflow.components.vectorstores.AstraDB import AstraDBVectorStoreComponent\nfrom langflow.components.vectorstores.base.model import LCVectorStoreComponent\nfrom langflow.field_typing import Embeddings, Text\nfrom langflow.schema import Record\n\n\nclass AstraDBSearchComponent(LCVectorStoreComponent):\n    display_name = \"Astra DB Search\"\n    description = \"Searches an existing Astra DB Vector Store.\"\n    icon = \"AstraDB\"\n    field_order = [\"token\", \"api_endpoint\", \"collection_name\", \"input_value\", \"embedding\"]\n\n    def build_config(self):\n        return {\n            \"search_type\": {\n                \"display_name\": \"Search Type\",\n                \"options\": [\"Similarity\", \"MMR\"],\n            },\n            \"input_value\": {\n                \"display_name\": \"Input Value\",\n                \"info\": \"Input value to search\",\n            },\n            \"embedding\": {\"display_name\": \"Embedding\", \"info\": \"Embedding to use\"},\n            \"collection_name\": {\n                \"display_name\": \"Collection Name\",\n                \"info\": \"The name of the collection within Astra DB where the vectors will be stored.\",\n            },\n            \"token\": {\n                \"display_name\": \"Token\",\n                \"info\": \"Authentication token for accessing Astra DB.\",\n                \"password\": True,\n            },\n            \"api_endpoint\": {\n                \"display_name\": \"API Endpoint\",\n                \"info\": \"API endpoint URL for the Astra DB service.\",\n            },\n            \"namespace\": {\n                \"display_name\": \"Namespace\",\n                \"info\": \"Optional namespace within Astra DB to use for the collection.\",\n                \"advanced\": True,\n            },\n            \"metric\": {\n                \"display_name\": \"Metric\",\n                \"info\": \"Optional distance metric for vector comparisons in the vector store.\",\n                \"advanced\": True,\n            },\n            \"batch_size\": {\n                \"display_name\": \"Batch Size\",\n                \"info\": \"Optional number of records to process in a single batch.\",\n                \"advanced\": True,\n            },\n            \"bulk_insert_batch_concurrency\": {\n                \"display_name\": \"Bulk Insert Batch Concurrency\",\n                \"info\": \"Optional concurrency level for bulk insert operations.\",\n                \"advanced\": True,\n            },\n            \"bulk_insert_overwrite_concurrency\": {\n                \"display_name\": \"Bulk Insert Overwrite Concurrency\",\n                \"info\": \"Optional concurrency level for bulk insert operations that overwrite existing records.\",\n                \"advanced\": True,\n            },\n            \"bulk_delete_concurrency\": {\n                \"display_name\": \"Bulk Delete Concurrency\",\n                \"info\": \"Optional concurrency level for bulk delete operations.\",\n                \"advanced\": True,\n            },\n            \"setup_mode\": {\n                \"display_name\": \"Setup Mode\",\n                \"info\": \"Configuration mode for setting up the vector store, with options like “Sync”, “Async”, or “Off”.\",\n                \"options\": [\"Sync\", \"Async\", \"Off\"],\n                \"advanced\": True,\n            },\n            \"pre_delete_collection\": {\n                \"display_name\": \"Pre Delete Collection\",\n                \"info\": \"Boolean flag to determine whether to delete the collection before creating a new one.\",\n                \"advanced\": True,\n            },\n            \"metadata_indexing_include\": {\n                \"display_name\": \"Metadata Indexing Include\",\n                \"info\": \"Optional list of metadata fields to include in the indexing.\",\n                \"advanced\": True,\n            },\n            \"metadata_indexing_exclude\": {\n                \"display_name\": \"Metadata Indexing Exclude\",\n                \"info\": \"Optional list of metadata fields to exclude from the indexing.\",\n                \"advanced\": True,\n            },\n            \"collection_indexing_policy\": {\n                \"display_name\": \"Collection Indexing Policy\",\n                \"info\": \"Optional dictionary defining the indexing policy for the collection.\",\n                \"advanced\": True,\n            },\n            \"number_of_results\": {\n                \"display_name\": \"Number of Results\",\n                \"info\": \"Number of results to return.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        embedding: Embeddings,\n        collection_name: str,\n        input_value: Text,\n        token: str,\n        api_endpoint: str,\n        search_type: str = \"Similarity\",\n        number_of_results: int = 4,\n        namespace: Optional[str] = None,\n        metric: Optional[str] = None,\n        batch_size: Optional[int] = None,\n        bulk_insert_batch_concurrency: Optional[int] = None,\n        bulk_insert_overwrite_concurrency: Optional[int] = None,\n        bulk_delete_concurrency: Optional[int] = None,\n        setup_mode: str = \"Sync\",\n        pre_delete_collection: bool = False,\n        metadata_indexing_include: Optional[List[str]] = None,\n        metadata_indexing_exclude: Optional[List[str]] = None,\n        collection_indexing_policy: Optional[dict] = None,\n    ) -> List[Record]:\n        vector_store = AstraDBVectorStoreComponent().build(\n            embedding=embedding,\n            collection_name=collection_name,\n            token=token,\n            api_endpoint=api_endpoint,\n            namespace=namespace,\n            metric=metric,\n            batch_size=batch_size,\n            bulk_insert_batch_concurrency=bulk_insert_batch_concurrency,\n            bulk_insert_overwrite_concurrency=bulk_insert_overwrite_concurrency,\n            bulk_delete_concurrency=bulk_delete_concurrency,\n            setup_mode=setup_mode,\n            pre_delete_collection=pre_delete_collection,\n            metadata_indexing_include=metadata_indexing_include,\n            metadata_indexing_exclude=metadata_indexing_exclude,\n            collection_indexing_policy=collection_indexing_policy,\n        )\n        try:\n            return self.search_with_vector_store(input_value, search_type, vector_store, k=number_of_results)\n        except KeyError as e:\n            if \"content\" in str(e):\n                raise ValueError(\n                    \"You should ingest data through Langflow (or LangChain) to query it in Langflow. Your collection does not contain a field name 'content'.\"\n                )\n            else:\n                raise e\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"collection_indexing_policy":{"type":"dict","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"collection_indexing_policy","display_name":"Collection Indexing Policy","advanced":true,"dynamic":false,"info":"Optional dictionary defining the indexing policy for the collection.","load_from_db":false,"title_case":false},"collection_name":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"collection_name","display_name":"Collection Name","advanced":false,"dynamic":false,"info":"The name of the collection within Astra DB where the vectors will be stored.","load_from_db":false,"title_case":false,"input_types":["Text"],"value":"framennet2"},"metadata_indexing_exclude":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"metadata_indexing_exclude","display_name":"Metadata Indexing Exclude","advanced":true,"dynamic":false,"info":"Optional list of metadata fields to exclude from the indexing.","load_from_db":false,"title_case":false,"input_types":["Text"]},"metadata_indexing_include":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"metadata_indexing_include","display_name":"Metadata Indexing Include","advanced":true,"dynamic":false,"info":"Optional list of metadata fields to include in the indexing.","load_from_db":false,"title_case":false,"input_types":["Text"]},"metric":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"metric","display_name":"Metric","advanced":true,"dynamic":false,"info":"Optional distance metric for vector comparisons in the vector store.","load_from_db":false,"title_case":false,"input_types":["Text"]},"namespace":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"namespace","display_name":"Namespace","advanced":true,"dynamic":false,"info":"Optional namespace within Astra DB to use for the collection.","load_from_db":false,"title_case":false,"input_types":["Text"]},"number_of_results":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":4,"fileTypes":[],"file_path":"","password":false,"name":"number_of_results","display_name":"Number of Results","advanced":true,"dynamic":false,"info":"Number of results to return.","load_from_db":false,"title_case":false},"pre_delete_collection":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"pre_delete_collection","display_name":"Pre Delete Collection","advanced":true,"dynamic":false,"info":"Boolean flag to determine whether to delete the collection before creating a new one.","load_from_db":false,"title_case":false},"search_type":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"Similarity","fileTypes":[],"file_path":"","password":false,"options":["Similarity","MMR"],"name":"search_type","display_name":"Search Type","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"setup_mode":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"Sync","fileTypes":[],"file_path":"","password":false,"options":["Sync","Async","Off"],"name":"setup_mode","display_name":"Setup Mode","advanced":true,"dynamic":false,"info":"Configuration mode for setting up the vector store, with options like “Sync”, “Async”, or “Off”.","load_from_db":false,"title_case":false,"input_types":["Text"]},"token":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":true,"name":"token","display_name":"Token","advanced":false,"dynamic":false,"info":"Authentication token for accessing Astra DB.","load_from_db":false,"title_case":false,"input_types":["Text"],"value":"AstraCS:XYZzweAZyiCujMsdtrpNwudT:3f040470c8b67a2942e87ec0bb4612a45859f7bb6b4aa497cfae3b0ea788a6ba"},"_type":"CustomComponent"},"description":"Searches an existing Astra DB Vector Store.","icon":"AstraDB","base_classes":["Record"],"display_name":"Astra DB Search","documentation":"","custom_fields":{"embedding":null,"collection_name":null,"input_value":null,"token":null,"api_endpoint":null,"search_type":null,"number_of_results":null,"namespace":null,"metric":null,"batch_size":null,"bulk_insert_batch_concurrency":null,"bulk_insert_overwrite_concurrency":null,"bulk_delete_concurrency":null,"setup_mode":null,"pre_delete_collection":null,"metadata_indexing_include":null,"metadata_indexing_exclude":null,"collection_indexing_policy":null},"output_types":["Record"],"field_formatters":{},"frozen":false,"field_order":["token","api_endpoint","collection_name","input_value","embedding"],"beta":false},"id":"AstraDBSearch-y9bNG"},"selected":false,"width":384,"height":721,"positionAbsolute":{"x":-920.0998977094329,"y":-426.7905927534177},"dragging":false},{"id":"OpenAIEmbeddings-bcgOs","type":"genericNode","position":{"x":-1465.5002478454921,"y":-294.37608757958867},"data":{"type":"OpenAIEmbeddings","node":{"template":{"allowed_special":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":[],"fileTypes":[],"file_path":"","password":false,"name":"allowed_special","display_name":"Allowed Special","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"chunk_size":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":1000,"fileTypes":[],"file_path":"","password":false,"name":"chunk_size","display_name":"Chunk Size","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Dict, List, Optional\n\nfrom langchain_openai.embeddings.base import OpenAIEmbeddings\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import Embeddings, NestedDict\n\n\nclass OpenAIEmbeddingsComponent(CustomComponent):\n    display_name = \"OpenAI Embeddings\"\n    description = \"Generate embeddings using OpenAI models.\"\n\n    def build_config(self):\n        return {\n            \"allowed_special\": {\n                \"display_name\": \"Allowed Special\",\n                \"advanced\": True,\n                \"field_type\": \"str\",\n                \"is_list\": True,\n            },\n            \"default_headers\": {\n                \"display_name\": \"Default Headers\",\n                \"advanced\": True,\n                \"field_type\": \"dict\",\n            },\n            \"default_query\": {\n                \"display_name\": \"Default Query\",\n                \"advanced\": True,\n                \"field_type\": \"NestedDict\",\n            },\n            \"disallowed_special\": {\n                \"display_name\": \"Disallowed Special\",\n                \"advanced\": True,\n                \"field_type\": \"str\",\n                \"is_list\": True,\n            },\n            \"chunk_size\": {\"display_name\": \"Chunk Size\", \"advanced\": True},\n            \"client\": {\"display_name\": \"Client\", \"advanced\": True},\n            \"deployment\": {\"display_name\": \"Deployment\", \"advanced\": True},\n            \"embedding_ctx_length\": {\n                \"display_name\": \"Embedding Context Length\",\n                \"advanced\": True,\n            },\n            \"max_retries\": {\"display_name\": \"Max Retries\", \"advanced\": True},\n            \"model\": {\n                \"display_name\": \"Model\",\n                \"advanced\": False,\n                \"options\": [\n                    \"text-embedding-3-small\",\n                    \"text-embedding-3-large\",\n                    \"text-embedding-ada-002\",\n                ],\n            },\n            \"model_kwargs\": {\"display_name\": \"Model Kwargs\", \"advanced\": True},\n            \"openai_api_base\": {\n                \"display_name\": \"OpenAI API Base\",\n                \"password\": True,\n                \"advanced\": True,\n            },\n            \"openai_api_key\": {\"display_name\": \"OpenAI API Key\", \"password\": True},\n            \"openai_api_type\": {\n                \"display_name\": \"OpenAI API Type\",\n                \"advanced\": True,\n                \"password\": True,\n            },\n            \"openai_api_version\": {\n                \"display_name\": \"OpenAI API Version\",\n                \"advanced\": True,\n            },\n            \"openai_organization\": {\n                \"display_name\": \"OpenAI Organization\",\n                \"advanced\": True,\n            },\n            \"openai_proxy\": {\"display_name\": \"OpenAI Proxy\", \"advanced\": True},\n            \"request_timeout\": {\"display_name\": \"Request Timeout\", \"advanced\": True},\n            \"show_progress_bar\": {\n                \"display_name\": \"Show Progress Bar\",\n                \"advanced\": True,\n            },\n            \"skip_empty\": {\"display_name\": \"Skip Empty\", \"advanced\": True},\n            \"tiktoken_model_name\": {\n                \"display_name\": \"TikToken Model Name\",\n                \"advanced\": True,\n            },\n            \"tiktoken_enable\": {\"display_name\": \"TikToken Enable\", \"advanced\": True},\n        }\n\n    def build(\n        self,\n        openai_api_key: str,\n        default_headers: Optional[Dict[str, str]] = None,\n        default_query: Optional[NestedDict] = {},\n        allowed_special: List[str] = [],\n        disallowed_special: List[str] = [\"all\"],\n        chunk_size: int = 1000,\n        deployment: str = \"text-embedding-ada-002\",\n        embedding_ctx_length: int = 8191,\n        max_retries: int = 6,\n        model: str = \"text-embedding-ada-002\",\n        model_kwargs: NestedDict = {},\n        openai_api_base: Optional[str] = None,\n        openai_api_type: Optional[str] = None,\n        openai_api_version: Optional[str] = None,\n        openai_organization: Optional[str] = None,\n        openai_proxy: Optional[str] = None,\n        request_timeout: Optional[float] = None,\n        show_progress_bar: bool = False,\n        skip_empty: bool = False,\n        tiktoken_enable: bool = True,\n        tiktoken_model_name: Optional[str] = None,\n    ) -> Embeddings:\n        # This is to avoid errors with Vector Stores (e.g Chroma)\n        if disallowed_special == [\"all\"]:\n            disallowed_special = \"all\"  # type: ignore\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n\n        return OpenAIEmbeddings(\n            tiktoken_enabled=tiktoken_enable,\n            default_headers=default_headers,\n            default_query=default_query,\n            allowed_special=set(allowed_special),\n            disallowed_special=\"all\",\n            chunk_size=chunk_size,\n            deployment=deployment,\n            embedding_ctx_length=embedding_ctx_length,\n            max_retries=max_retries,\n            model=model,\n            model_kwargs=model_kwargs,\n            base_url=openai_api_base,\n            api_key=api_key,\n            openai_api_type=openai_api_type,\n            api_version=openai_api_version,\n            organization=openai_organization,\n            openai_proxy=openai_proxy,\n            timeout=request_timeout,\n            show_progress_bar=show_progress_bar,\n            skip_empty=skip_empty,\n            tiktoken_model_name=tiktoken_model_name,\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"default_headers":{"type":"dict","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"default_headers","display_name":"Default Headers","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"default_query":{"type":"NestedDict","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":{},"fileTypes":[],"file_path":"","password":false,"name":"default_query","display_name":"Default Query","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"deployment":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"text-embedding-ada-002","fileTypes":[],"file_path":"","password":false,"name":"deployment","display_name":"Deployment","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"disallowed_special":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":["all"],"fileTypes":[],"file_path":"","password":false,"name":"disallowed_special","display_name":"Disallowed Special","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"embedding_ctx_length":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":8191,"fileTypes":[],"file_path":"","password":false,"name":"embedding_ctx_length","display_name":"Embedding Context Length","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"max_retries":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":6,"fileTypes":[],"file_path":"","password":false,"name":"max_retries","display_name":"Max Retries","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"model":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"text-embedding-ada-002","fileTypes":[],"file_path":"","password":false,"options":["text-embedding-3-small","text-embedding-3-large","text-embedding-ada-002"],"name":"model","display_name":"Model","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"model_kwargs":{"type":"NestedDict","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":{},"fileTypes":[],"file_path":"","password":false,"name":"model_kwargs","display_name":"Model Kwargs","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"openai_api_base":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":true,"name":"openai_api_base","display_name":"OpenAI API Base","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"openai_api_key":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":true,"name":"openai_api_key","display_name":"OpenAI API Key","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"],"value":"sk-proj-YOHXL18tXImZPxGWzofiT3BlbkFJUObsIpOxllEB2PfFlNkb"},"openai_api_type":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":true,"name":"openai_api_type","display_name":"OpenAI API Type","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"openai_api_version":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"openai_api_version","display_name":"OpenAI API Version","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"openai_organization":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"openai_organization","display_name":"OpenAI Organization","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"openai_proxy":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"openai_proxy","display_name":"OpenAI Proxy","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"request_timeout":{"type":"float","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"request_timeout","display_name":"Request Timeout","advanced":true,"dynamic":false,"info":"","rangeSpec":{"step_type":"float","min":-1,"max":1,"step":0.1},"load_from_db":false,"title_case":false},"show_progress_bar":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"show_progress_bar","display_name":"Show Progress Bar","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"skip_empty":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"skip_empty","display_name":"Skip Empty","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"tiktoken_enable":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":true,"fileTypes":[],"file_path":"","password":false,"name":"tiktoken_enable","display_name":"TikToken Enable","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"tiktoken_model_name":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"tiktoken_model_name","display_name":"TikToken Model Name","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Generate embeddings using OpenAI models.","base_classes":["Embeddings"],"display_name":"OpenAI Embeddings","documentation":"","custom_fields":{"openai_api_key":null,"default_headers":null,"default_query":null,"allowed_special":null,"disallowed_special":null,"chunk_size":null,"deployment":null,"embedding_ctx_length":null,"max_retries":null,"model":null,"model_kwargs":null,"openai_api_base":null,"openai_api_type":null,"openai_api_version":null,"openai_organization":null,"openai_proxy":null,"request_timeout":null,"show_progress_bar":null,"skip_empty":null,"tiktoken_enable":null,"tiktoken_model_name":null},"output_types":["Embeddings"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"OpenAIEmbeddings-bcgOs"},"selected":false,"width":384,"height":391,"positionAbsolute":{"x":-1465.5002478454921,"y":-294.37608757958867},"dragging":false},{"id":"File-5dQ9j","type":"genericNode","position":{"x":-945.9400332228626,"y":-896.3500887532929},"data":{"type":"File","node":{"template":{"path":{"type":"file","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[".txt",".md",".mdx",".csv",".json",".yaml",".yml",".xml",".html",".htm",".pdf",".docx",".py",".sh",".sql",".js",".ts",".tsx"],"file_path":"acff2724-a74e-4ff8-9d82-58616d606c7f/FrameNet All.pdf","password":false,"name":"path","display_name":"Path","advanced":false,"dynamic":false,"info":"Supported file types: txt, md, mdx, csv, json, yaml, yml, xml, html, htm, pdf, docx, py, sh, sql, js, ts, tsx","load_from_db":false,"title_case":false,"value":""},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from pathlib import Path\nfrom typing import Any, Dict\n\nfrom langflow.base.data.utils import TEXT_FILE_TYPES, parse_text_file_to_record\nfrom langflow.custom import CustomComponent\nfrom langflow.schema import Record\n\n\nclass FileComponent(CustomComponent):\n    display_name = \"File\"\n    description = \"A generic file loader.\"\n    icon = \"file-text\"\n\n    def build_config(self) -> Dict[str, Any]:\n        return {\n            \"path\": {\n                \"display_name\": \"Path\",\n                \"field_type\": \"file\",\n                \"file_types\": TEXT_FILE_TYPES,\n                \"info\": f\"Supported file types: {', '.join(TEXT_FILE_TYPES)}\",\n            },\n            \"silent_errors\": {\n                \"display_name\": \"Silent Errors\",\n                \"advanced\": True,\n                \"info\": \"If true, errors will not raise an exception.\",\n            },\n        }\n\n    def load_file(self, path: str, silent_errors: bool = False) -> Record:\n        resolved_path = self.resolve_path(path)\n        path_obj = Path(resolved_path)\n        extension = path_obj.suffix[1:].lower()\n        if extension == \"doc\":\n            raise ValueError(\"doc files are not supported. Please save as .docx\")\n        if extension not in TEXT_FILE_TYPES:\n            raise ValueError(f\"Unsupported file type: {extension}\")\n        record = parse_text_file_to_record(resolved_path, silent_errors)\n        self.status = record if record else \"No data\"\n        return record or Record()\n\n    def build(\n        self,\n        path: str,\n        silent_errors: bool = False,\n    ) -> Record:\n        record = self.load_file(path, silent_errors)\n        self.status = record\n        return record\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"silent_errors":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"silent_errors","display_name":"Silent Errors","advanced":true,"dynamic":false,"info":"If true, errors will not raise an exception.","load_from_db":false,"title_case":false},"_type":"CustomComponent"},"description":"A generic file loader.","icon":"file-text","base_classes":["Record"],"display_name":"File","documentation":"","custom_fields":{"path":null,"silent_errors":null},"output_types":["Record"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"File-5dQ9j"},"selected":false,"width":384,"height":287,"dragging":false,"positionAbsolute":{"x":-945.9400332228626,"y":-896.3500887532929}},{"id":"TextInput-Fp31S","type":"genericNode","position":{"x":-1876.459506372982,"y":515.9682838852522},"data":{"type":"TextInput","node":{"template":{"input_value":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"","fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Text","advanced":false,"input_types":["Record","Text"],"dynamic":false,"info":"Text or Record to be passed as input.","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional\n\nfrom langflow.base.io.text import TextComponent\nfrom langflow.field_typing import Text\n\n\nclass TextInput(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n\n    def build_config(self):\n        return {\n            \"input_value\": {\n                \"display_name\": \"Text\",\n                \"input_types\": [\"Record\", \"Text\"],\n                \"info\": \"Text or Record to be passed as input.\",\n            },\n            \"record_template\": {\n                \"display_name\": \"Record Template\",\n                \"multiline\": True,\n                \"info\": \"Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        input_value: Optional[Text] = \"\",\n        record_template: Optional[str] = \"\",\n    ) -> Text:\n        return super().build(input_value=input_value, record_template=record_template)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"record_template":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"record_template","display_name":"Record Template","advanced":true,"dynamic":false,"info":"Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Get text inputs from the Playground.","icon":"type","base_classes":["object","str","Text"],"display_name":"Text Input","documentation":"","custom_fields":{"input_value":null,"record_template":null},"output_types":["Text"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"TextInput-Fp31S"},"selected":false,"width":384,"height":297,"positionAbsolute":{"x":-1876.459506372982,"y":515.9682838852522},"dragging":false},{"id":"RecordsToText-IcWx3","type":"genericNode","position":{"x":-1614.8565681258756,"y":123.69765931944946},"data":{"type":"RecordsToText","node":{"template":{"records":{"type":"Record","required":true,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"records","display_name":"Records","advanced":false,"dynamic":false,"info":"The records to convert to text.","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.custom import CustomComponent\nfrom langflow.field_typing import Text\nfrom langflow.helpers.record import records_to_text\nfrom langflow.schema import Record\n\n\nclass RecordsToTextComponent(CustomComponent):\n    display_name = \"Records To Text\"\n    description = \"Convert Records into plain text following a specified template.\"\n\n    def build_config(self):\n        return {\n            \"records\": {\n                \"display_name\": \"Records\",\n                \"info\": \"The records to convert to text.\",\n            },\n            \"template\": {\n                \"display_name\": \"Template\",\n                \"info\": \"The template to use for formatting the records. It can contain the keys {text}, {data} or any other key in the Record.\",\n                \"multiline\": True,\n            },\n        }\n\n    def build(\n        self,\n        records: list[Record],\n        template: str = \"Text: {text}\\nData: {data}\",\n    ) -> Text:\n        if not records:\n            return \"\"\n        if isinstance(records, Record):\n            records = [records]\n\n        result_string = records_to_text(template, records)\n        self.status = result_string\n        return result_string\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"template":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"Text: {text}\\nData: {data}","fileTypes":[],"file_path":"","password":false,"name":"template","display_name":"Template","advanced":false,"dynamic":false,"info":"The template to use for formatting the records. It can contain the keys {text}, {data} or any other key in the Record.","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Convert Records into plain text following a specified template.","base_classes":["object","str","Text"],"display_name":"Records To Text","documentation":"","custom_fields":{"records":null,"template":null},"output_types":["Text"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"RecordsToText-IcWx3"},"selected":false,"width":384,"height":373,"positionAbsolute":{"x":-1614.8565681258756,"y":123.69765931944946},"dragging":false},{"id":"ChatInput-VkZj0","type":"genericNode","position":{"x":-2393.125427927299,"y":570.100008450621},"data":{"type":"ChatInput","node":{"template":{"files":{"type":"file","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[".txt",".md",".mdx",".csv",".json",".yaml",".yml",".xml",".html",".htm",".pdf",".docx",".py",".sh",".sql",".js",".ts",".tsx",".jpg",".jpeg",".png",".bmp"],"file_path":"","password":false,"name":"files","display_name":"Files","advanced":true,"dynamic":false,"info":"Files to be sent with the message.","load_from_db":false,"title_case":false,"value":""},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.schema.message import Message\nfrom langflow.field_typing import Text\nfrom typing import Union\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n\n    def build_config(self):\n        build_config = super().build_config()\n        build_config[\"input_value\"] = {\n            \"input_types\": [],\n            \"display_name\": \"Text\",\n            \"multiline\": True,\n        }\n        build_config[\"return_message\"] = {\n            \"display_name\": \"Return Record\",\n            \"advanced\": True,\n        }\n\n        return build_config\n\n    def build(\n        self,\n        sender: Optional[str] = \"User\",\n        sender_name: Optional[str] = \"User\",\n        input_value: Optional[str] = None,\n        files: Optional[list[str]] = None,\n        session_id: Optional[str] = None,\n        return_message: Optional[bool] = True,\n    ) -> Union[Message, Text]:\n        return input_value\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Text","advanced":false,"input_types":[],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"value":"Define the \"Go_into_shape\" frame"},"return_message":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":true,"fileTypes":[],"file_path":"","password":false,"name":"return_message","display_name":"Return Record","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"sender":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"User","fileTypes":[],"file_path":"","password":false,"options":["Machine","User"],"name":"sender","display_name":"Sender Type","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"sender_name":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"User","fileTypes":[],"file_path":"","password":false,"name":"sender_name","display_name":"Sender Name","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"session_id":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"session_id","display_name":"Session ID","advanced":true,"dynamic":false,"info":"If provided, the message will be stored in the memory.","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Get chat inputs from the Playground.","icon":"ChatInput","base_classes":["Message","object","str","Text"],"display_name":"Chat Input","documentation":"","custom_fields":{"sender":null,"sender_name":null,"input_value":null,"files":null,"session_id":null,"return_message":null},"output_types":["Message","Text"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false,"edited":true},"id":"ChatInput-VkZj0","description":"Get chat inputs from the Playground.","display_name":"Chat Input"},"selected":false,"width":384,"height":289,"positionAbsolute":{"x":-2393.125427927299,"y":570.100008450621},"dragging":false}],"edges":[{"source":"OpenAIModel-yvC5c","sourceHandle":"{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-yvC5cœ}","target":"ChatOutput-KoSL6","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-KoSL6œ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"ChatOutput-KoSL6","inputTypes":["Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"OpenAIModel","id":"OpenAIModel-yvC5c"}},"style":{"stroke":"#555"},"className":"","id":"reactflow__edge-OpenAIModel-yvC5c{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-yvC5cœ}-ChatOutput-KoSL6{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-KoSL6œ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}"},{"source":"OpenAIEmbeddings-78poi","sourceHandle":"{œbaseClassesœ:[œEmbeddingsœ],œdataTypeœ:œOpenAIEmbeddingsœ,œidœ:œOpenAIEmbeddings-78poiœ}","target":"AstraDB-qYfmn","targetHandle":"{œfieldNameœ:œembeddingœ,œidœ:œAstraDB-qYfmnœ,œinputTypesœ:null,œtypeœ:œEmbeddingsœ}","data":{"targetHandle":{"fieldName":"embedding","id":"AstraDB-qYfmn","inputTypes":null,"type":"Embeddings"},"sourceHandle":{"baseClasses":["Embeddings"],"dataType":"OpenAIEmbeddings","id":"OpenAIEmbeddings-78poi"}},"style":{"stroke":"#555"},"className":"","id":"reactflow__edge-OpenAIEmbeddings-78poi{œbaseClassesœ:[œEmbeddingsœ],œdataTypeœ:œOpenAIEmbeddingsœ,œidœ:œOpenAIEmbeddings-78poiœ}-AstraDB-qYfmn{œfieldNameœ:œembeddingœ,œidœ:œAstraDB-qYfmnœ,œinputTypesœ:null,œtypeœ:œEmbeddingsœ}"},{"source":"AstraDBSearch-y9bNG","sourceHandle":"{œbaseClassesœ:[œRecordœ],œdataTypeœ:œAstraDBSearchœ,œidœ:œAstraDBSearch-y9bNGœ}","target":"Prompt-wb1Kn","targetHandle":"{œfieldNameœ:œContextœ,œidœ:œPrompt-wb1Knœ,œinputTypesœ:[œDocumentœ,œRecordœ,œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"Context","id":"Prompt-wb1Kn","inputTypes":["Document","Record","Text"],"type":"str"},"sourceHandle":{"baseClasses":["Record"],"dataType":"AstraDBSearch","id":"AstraDBSearch-y9bNG"}},"style":{"stroke":"#555"},"className":"","id":"reactflow__edge-AstraDBSearch-y9bNG{œbaseClassesœ:[œRecordœ],œdataTypeœ:œAstraDBSearchœ,œidœ:œAstraDBSearch-y9bNGœ}-Prompt-wb1Kn{œfieldNameœ:œContextœ,œidœ:œPrompt-wb1Knœ,œinputTypesœ:[œDocumentœ,œRecordœ,œTextœ],œtypeœ:œstrœ}"},{"source":"CharacterTextSplitter-Q5DKn","sourceHandle":"{œbaseClassesœ:[œRecordœ],œdataTypeœ:œCharacterTextSplitterœ,œidœ:œCharacterTextSplitter-Q5DKnœ}","target":"AstraDB-qYfmn","targetHandle":"{œfieldNameœ:œinputsœ,œidœ:œAstraDB-qYfmnœ,œinputTypesœ:null,œtypeœ:œRecordœ}","data":{"targetHandle":{"fieldName":"inputs","id":"AstraDB-qYfmn","inputTypes":null,"type":"Record"},"sourceHandle":{"baseClasses":["Record"],"dataType":"CharacterTextSplitter","id":"CharacterTextSplitter-Q5DKn"}},"style":{"stroke":"#555"},"className":"","id":"reactflow__edge-CharacterTextSplitter-Q5DKn{œbaseClassesœ:[œRecordœ],œdataTypeœ:œCharacterTextSplitterœ,œidœ:œCharacterTextSplitter-Q5DKnœ}-AstraDB-qYfmn{œfieldNameœ:œinputsœ,œidœ:œAstraDB-qYfmnœ,œinputTypesœ:null,œtypeœ:œRecordœ}"},{"source":"File-5dQ9j","sourceHandle":"{œbaseClassesœ:[œRecordœ],œdataTypeœ:œFileœ,œidœ:œFile-5dQ9jœ}","target":"CharacterTextSplitter-Q5DKn","targetHandle":"{œfieldNameœ:œinputsœ,œidœ:œCharacterTextSplitter-Q5DKnœ,œinputTypesœ:[œDocumentœ,œRecordœ],œtypeœ:œRecordœ}","data":{"targetHandle":{"fieldName":"inputs","id":"CharacterTextSplitter-Q5DKn","inputTypes":["Document","Record"],"type":"Record"},"sourceHandle":{"baseClasses":["Record"],"dataType":"File","id":"File-5dQ9j"}},"style":{"stroke":"#555"},"className":"","id":"reactflow__edge-File-5dQ9j{œbaseClassesœ:[œRecordœ],œdataTypeœ:œFileœ,œidœ:œFile-5dQ9jœ}-CharacterTextSplitter-Q5DKn{œfieldNameœ:œinputsœ,œidœ:œCharacterTextSplitter-Q5DKnœ,œinputTypesœ:[œDocumentœ,œRecordœ],œtypeœ:œRecordœ}"},{"source":"OpenAIEmbeddings-bcgOs","sourceHandle":"{œbaseClassesœ:[œEmbeddingsœ],œdataTypeœ:œOpenAIEmbeddingsœ,œidœ:œOpenAIEmbeddings-bcgOsœ}","target":"AstraDBSearch-y9bNG","targetHandle":"{œfieldNameœ:œembeddingœ,œidœ:œAstraDBSearch-y9bNGœ,œinputTypesœ:null,œtypeœ:œEmbeddingsœ}","data":{"targetHandle":{"fieldName":"embedding","id":"AstraDBSearch-y9bNG","inputTypes":null,"type":"Embeddings"},"sourceHandle":{"baseClasses":["Embeddings"],"dataType":"OpenAIEmbeddings","id":"OpenAIEmbeddings-bcgOs"}},"id":"reactflow__edge-OpenAIEmbeddings-bcgOs{œbaseClassesœ:[œEmbeddingsœ],œdataTypeœ:œOpenAIEmbeddingsœ,œidœ:œOpenAIEmbeddings-bcgOsœ}-AstraDBSearch-y9bNG{œfieldNameœ:œembeddingœ,œidœ:œAstraDBSearch-y9bNGœ,œinputTypesœ:null,œtypeœ:œEmbeddingsœ}","className":""},{"source":"TextInput-Fp31S","sourceHandle":"{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œTextInputœ,œidœ:œTextInput-Fp31Sœ}","target":"Prompt-wb1Kn","targetHandle":"{œfieldNameœ:œQuestionœ,œidœ:œPrompt-wb1Knœ,œinputTypesœ:[œDocumentœ,œRecordœ,œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"Question","id":"Prompt-wb1Kn","inputTypes":["Document","Record","Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"TextInput","id":"TextInput-Fp31S"}},"id":"reactflow__edge-TextInput-Fp31S{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œTextInputœ,œidœ:œTextInput-Fp31Sœ}-Prompt-wb1Kn{œfieldNameœ:œQuestionœ,œidœ:œPrompt-wb1Knœ,œinputTypesœ:[œDocumentœ,œRecordœ,œTextœ],œtypeœ:œstrœ}","className":""},{"source":"Prompt-wb1Kn","sourceHandle":"{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œPromptœ,œidœ:œPrompt-wb1Knœ}","target":"OpenAIModel-yvC5c","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-yvC5cœ,œinputTypesœ:[œTextœ,œRecordœ,œPromptœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"OpenAIModel-yvC5c","inputTypes":["Text","Record","Prompt"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"Prompt","id":"Prompt-wb1Kn"}},"id":"reactflow__edge-Prompt-wb1Kn{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œPromptœ,œidœ:œPrompt-wb1Knœ}-OpenAIModel-yvC5c{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-yvC5cœ,œinputTypesœ:[œTextœ,œRecordœ,œPromptœ],œtypeœ:œstrœ}","className":""},{"source":"TextInput-Fp31S","sourceHandle":"{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œTextInputœ,œidœ:œTextInput-Fp31Sœ}","target":"AstraDBSearch-y9bNG","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œAstraDBSearch-y9bNGœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"AstraDBSearch-y9bNG","inputTypes":["Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"TextInput","id":"TextInput-Fp31S"}},"id":"reactflow__edge-TextInput-Fp31S{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œTextInputœ,œidœ:œTextInput-Fp31Sœ}-AstraDBSearch-y9bNG{œfieldNameœ:œinput_valueœ,œidœ:œAstraDBSearch-y9bNGœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}","className":""},{"source":"ChatInput-VkZj0","sourceHandle":"{œbaseClassesœ:[œMessageœ,œobjectœ,œstrœ,œTextœ],œdataTypeœ:œChatInputœ,œidœ:œChatInput-VkZj0œ}","target":"TextInput-Fp31S","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œTextInput-Fp31Sœ,œinputTypesœ:[œRecordœ,œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"TextInput-Fp31S","inputTypes":["Record","Text"],"type":"str"},"sourceHandle":{"baseClasses":["Message","object","str","Text"],"dataType":"ChatInput","id":"ChatInput-VkZj0"}},"id":"reactflow__edge-ChatInput-VkZj0{œbaseClassesœ:[œMessageœ,œobjectœ,œstrœ,œTextœ],œdataTypeœ:œChatInputœ,œidœ:œChatInput-VkZj0œ}-TextInput-Fp31S{œfieldNameœ:œinput_valueœ,œidœ:œTextInput-Fp31Sœ,œinputTypesœ:[œRecordœ,œTextœ],œtypeœ:œstrœ}","className":""}],"viewport":{"x":330.240959207165,"y":83.94244625967372,"zoom":0.5431793798903973}},"description":"Language Models, Mapped and Mastered.","name":"FrameNetChatFinal","last_tested_version":"1.0.0a57","is_component":false}